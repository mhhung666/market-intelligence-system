"""
Ollama å¸‚å ´åˆ†æå™¨
ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹é€²è¡Œå¿«é€Ÿå¸‚å ´æ•¸æ“šé è™•ç†å’Œç¯©é¸
"""

import os
import re
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime

try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    print("è­¦å‘Š: ollama å¥—ä»¶æœªå®‰è£,è«‹åŸ·è¡Œ: pip install ollama")

from .analyzer_base import AnalyzerBase


class OllamaAnalyzer(AnalyzerBase):
    """
    Ollama å¸‚å ´åˆ†æå™¨

    è² è²¬å¿«é€Ÿè™•ç†å¸‚å ´åˆ†æä»»å‹™:
    - å¸‚å ´æŒ‡æ•¸å¿«é€Ÿæ‘˜è¦
    - å¤§é‡æ–°èåˆæ­¥ç¯©é¸
    - æ–°èæƒ…ç·’åˆ†æ
    - é—œéµå­—æå–

    å„ªå‹¢: æœ¬åœ°é‹è¡Œã€å…è²»ã€å¿«é€Ÿ
    ç”¨é€”: é è™•ç†å¤§é‡å¸‚å ´è³‡æ–™,æ¸›å°‘ Claude API èª¿ç”¨æˆæœ¬
    """

    def __init__(self, model: str = "llama3.1:8b", host: str = "http://localhost:11434", config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ– Ollama åˆ†æå™¨

        Args:
            model: Ollama æ¨¡å‹åç¨± (æ¨è–¦: llama3.1:8b, qwen2.5:14b)
            host: Ollama æœå‹™åœ°å€
            config: é…ç½®å­—å…¸
        """
        super().__init__(name="Ollama", config=config)
        self.model = model
        self.host = host
        self._inference_count = 0

    def initialize(self) -> bool:
        """
        åˆå§‹åŒ– Ollama å®¢æˆ¶ç«¯ä¸¦æª¢æŸ¥æ¨¡å‹å¯ç”¨æ€§

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        if not OLLAMA_AVAILABLE:
            print("éŒ¯èª¤: ollama å¥—ä»¶æœªå®‰è£")
            return False

        try:
            # æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œ
            models = ollama.list()
            available_models = [m['name'] for m in models.get('models', [])]

            if not any(self.model in m for m in available_models):
                print(f"è­¦å‘Š: æ¨¡å‹ {self.model} æœªå®‰è£")
                print(f"å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
                print(f"è«‹åŸ·è¡Œ: ollama pull {self.model}")
                return False

            self._initialized = True
            print(f"âœ“ Ollama å¸‚å ´åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {self.model})")
            return True

        except Exception as e:
            print(f"éŒ¯èª¤: Ollama åˆå§‹åŒ–å¤±æ•— - {e}")
            print("è«‹ç¢ºèª Ollama æœå‹™æ­£åœ¨é‹è¡Œ: ollama serve")
            return False

    def _generate(self, prompt: str, system: Optional[str] = None, max_tokens: int = 2048, temperature: float = 0.7) -> Optional[str]:
        """
        å‘¼å« Ollama ç”Ÿæˆ

        Args:
            prompt: æç¤ºæ–‡å­—
            system: ç³»çµ±æç¤º (å¯é¸)
            max_tokens: æœ€å¤§ token æ•¸
            temperature: æº«åº¦åƒæ•¸

        Returns:
            Optional[str]: ç”Ÿæˆçš„æ–‡å­—,å¤±æ•—è¿”å› None
        """
        if not self._initialized:
            print("éŒ¯èª¤: Ollama åˆ†æå™¨æœªåˆå§‹åŒ–")
            return None

        try:
            options = {
                'num_predict': max_tokens,
                'temperature': temperature,
            }

            response = ollama.generate(
                model=self.model,
                prompt=prompt,
                system=system,
                options=options
            )

            self._inference_count += 1
            return response['response']

        except Exception as e:
            print(f"éŒ¯èª¤: Ollama ç”Ÿæˆå¤±æ•— - {e}")
            return None

    def analyze_market_indices(self, data_path: str, **kwargs) -> str:
        """
        åˆ†æå¸‚å ´æŒ‡æ•¸æ•¸æ“š (å¿«é€Ÿæ‘˜è¦)

        Args:
            data_path: å¸‚å ´æŒ‡æ•¸æ•¸æ“šæª”æ¡ˆè·¯å¾‘
            **kwargs: é¡å¤–åƒæ•¸
                - regions: é—œæ³¨çš„åœ°å€åˆ—è¡¨
                - focus: åˆ†æé‡é»

        Returns:
            str: åˆ†æçµæœ (Markdown æ ¼å¼)
        """
        if not self._initialized:
            return "éŒ¯èª¤: Ollama åˆ†æå™¨æœªåˆå§‹åŒ–"

        try:
            with open(data_path, 'r', encoding='utf-8') as f:
                market_data = f.read()

            regions = kwargs.get('regions', ['å…¨çƒ'])
            focus = kwargs.get('focus', 'trend')

            system = "ä½ æ˜¯ä¸€ä½å¸‚å ´åˆ†æåŠ©æ‰‹ã€‚è«‹æä¾›ç°¡æ½”çš„å¸‚å ´æ‘˜è¦,é‡é»é—œæ³¨é—œéµè¶¨å‹¢å’Œç•°å¸¸è®ŠåŒ–ã€‚"

            prompt = f"""è«‹åˆ†æä»¥ä¸‹å…¨çƒå¸‚å ´æŒ‡æ•¸æ•¸æ“šä¸¦æä¾›ç°¡çŸ­æ‘˜è¦ (300å­—ä»¥å…§):

{market_data}

é—œæ³¨åœ°å€: {', '.join(regions)}
åˆ†æé‡é»: {focus}

è«‹æä¾›:
1. æ•´é«”å¸‚å ´èµ°å‹¢ (æ¼²/è·Œ)
2. è¡¨ç¾æœ€å¥½å’Œæœ€å·®çš„åœ°å€
3. éœ€è¦æ³¨æ„çš„ç•°å¸¸è®ŠåŒ–

æ‘˜è¦:"""

            result = self._generate(prompt, system=system, max_tokens=512, temperature=0.5)
            return result or "åˆ†æå¤±æ•—"

        except Exception as e:
            return f"éŒ¯èª¤: åˆ†æå¸‚å ´æŒ‡æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤ - {e}"

    def analyze_market_news(self, news_items: List[Dict[str, Any]], **kwargs) -> str:
        """
        åˆ†æå¸‚å ´æ–°è (ç¯©é¸é‡è¦æ–°è)

        Args:
            news_items: æ–°èé …ç›®åˆ—è¡¨
            **kwargs: é¡å¤–åƒæ•¸
                - top_k: è¿”å›å‰ K å‰‡æ–°è (é è¨­: 10)
                - sentiment: æ˜¯å¦åŒ…å«æƒ…ç·’åˆ†æ

        Returns:
            str: ç¯©é¸å¾Œçš„é‡è¦æ–°è (Markdown æ ¼å¼)
        """
        if not self._initialized:
            return "éŒ¯èª¤: Ollama åˆ†æå™¨æœªåˆå§‹åŒ–"

        top_k = kwargs.get('top_k', 10)
        include_sentiment = kwargs.get('sentiment', True)

        # ä½¿ç”¨ Ollama è©•ä¼°æ¯å‰‡æ–°èçš„é‡è¦æ€§
        scored_news = []
        print(f"é–‹å§‹ç¯©é¸ {len(news_items)} å‰‡æ–°è...")

        for i, item in enumerate(news_items, 1):
            if i % 10 == 0:
                print(f"  è™•ç†é€²åº¦: {i}/{len(news_items)}")

            title = item.get('title', '')
            importance = self._rate_news_importance(title, item.get('summary', ''))

            result = {
                'news': item,
                'importance': importance
            }

            if include_sentiment:
                sentiment = self.sentiment_analysis(title)
                result['sentiment'] = sentiment

            scored_news.append(result)

        # æ’åºä¸¦å–å‰ K å‰‡
        scored_news.sort(key=lambda x: x['importance'], reverse=True)
        top_news = scored_news[:top_k]

        # æ ¼å¼åŒ–è¼¸å‡º
        lines = ["# é‡è¦æ–°èç¯©é¸çµæœ\n"]
        lines.append(f"> å¾ {len(news_items)} å‰‡æ–°èä¸­ç¯©é¸å‡ºæœ€é‡è¦çš„ {len(top_news)} å‰‡\n")

        for i, item in enumerate(top_news, 1):
            news = item['news']
            importance = item['importance']
            lines.append(f"## {i}. {news.get('title', 'ç„¡æ¨™é¡Œ')} (é‡è¦æ€§: {importance}/10)")

            if include_sentiment and 'sentiment' in item:
                sentiment_emoji = {'positive': 'ğŸ“ˆ', 'negative': 'ğŸ“‰', 'neutral': 'â¡ï¸'}
                sentiment = item['sentiment']['sentiment']
                lines.append(f"**æƒ…ç·’**: {sentiment_emoji.get(sentiment, 'â¡ï¸')} {sentiment}")

            if summary := news.get('summary'):
                lines.append(f"\n{summary}\n")

            if source := news.get('source'):
                lines.append(f"*ä¾†æº: {source}*\n")

        return '\n'.join(lines)

    def analyze_holdings_performance(self, holdings_data: Dict[str, Any], **kwargs) -> str:
        """
        åˆ†ææŒè‚¡è¡¨ç¾ (å¿«é€Ÿè©•ä¼°)

        Args:
            holdings_data: æŒè‚¡åƒ¹æ ¼æ•¸æ“š
            **kwargs: é¡å¤–åƒæ•¸
                - benchmark: åŸºæº–æŒ‡æ•¸

        Returns:
            str: åˆ†æçµæœ (Markdown æ ¼å¼)
        """
        if not self._initialized:
            return "éŒ¯èª¤: Ollama åˆ†æå™¨æœªåˆå§‹åŒ–"

        benchmark = kwargs.get('benchmark', '^GSPC')

        system = "ä½ æ˜¯ä¸€ä½æŠ•è³‡çµ„åˆåˆ†æåŠ©æ‰‹ã€‚æä¾›ç°¡æ½”çš„æŒè‚¡è¡¨ç¾è©•ä¼°ã€‚"

        holdings_text = self._format_holdings_data(holdings_data)

        prompt = f"""è«‹ç°¡è¦åˆ†æä»¥ä¸‹æŒè‚¡è¡¨ç¾ (200å­—ä»¥å…§):

{holdings_text}

åŸºæº–æŒ‡æ•¸: {benchmark}

è«‹æä¾›:
1. æ•´é«”è¡¨ç¾è©•ä¼°
2. è¡¨ç¾æœ€å¥½çš„ 2-3 æª”
3. è¡¨ç¾æœ€å·®çš„ 2-3 æª”

è©•ä¼°:"""

        result = self._generate(prompt, system=system, max_tokens=512, temperature=0.5)
        return result or "åˆ†æå¤±æ•—"

    def _rate_news_importance(self, title: str, summary: str) -> int:
        """
        è©•ä¼°æ–°èé‡è¦æ€§

        Args:
            title: æ–°èæ¨™é¡Œ
            summary: æ–°èæ‘˜è¦

        Returns:
            int: é‡è¦æ€§è©•åˆ† (1-10)
        """
        system = "ä½ æ˜¯æ–°èåˆ†æå°ˆå®¶ã€‚è©•ä¼°æ–°èå°å¸‚å ´çš„é‡è¦æ€§ã€‚"

        prompt = f"""è«‹è©•ä¼°ä»¥ä¸‹æ–°èçš„å¸‚å ´é‡è¦æ€§ (1-10åˆ†):

æ¨™é¡Œ: {title}
æ‘˜è¦: {summary[:200]}

åªå›ç­”ä¸€å€‹æ•¸å­— (1-10),ä¸éœ€è¦å…¶ä»–æ–‡å­—ã€‚

è©•åˆ†:"""

        result = self._generate(prompt, system=system, max_tokens=10, temperature=0.3)

        # æå–æ•¸å­—
        if result:
            match = re.search(r'\d+', result)
            if match:
                score = int(match.group())
                return min(max(score, 1), 10)  # é™åˆ¶åœ¨ 1-10 ä¹‹é–“

        return 5  # é è¨­ä¸­ç­‰é‡è¦æ€§

    def sentiment_analysis(self, text: str, **kwargs) -> Dict[str, Any]:
        """
        æƒ…ç·’åˆ†æ

        Args:
            text: è¦åˆ†æçš„æ–‡å­—
            **kwargs: é¡å¤–åƒæ•¸

        Returns:
            Dict[str, Any]: æƒ…ç·’åˆ†æçµæœ
        """
        if not self._initialized:
            return super().sentiment_analysis(text, **kwargs)

        system = "ä½ æ˜¯æƒ…ç·’åˆ†æå°ˆå®¶ã€‚åˆ†ææ–‡å­—çš„æ•´é«”æƒ…ç·’å‚¾å‘ã€‚"

        prompt = f"""è«‹åˆ†æä»¥ä¸‹æ–‡å­—çš„æƒ…ç·’:

{text[:500]}

åªå›ç­”ä»¥ä¸‹æ ¼å¼:
æƒ…ç·’: [positive/negative/neutral]
åˆ†æ•¸: [-1.0 åˆ° 1.0]
ä¿¡å¿ƒ: [0.0 åˆ° 1.0]

åˆ†æ:"""

        result = self._generate(prompt, system=system, max_tokens=128, temperature=0.3)

        # è§£æçµæœ
        if result:
            sentiment = 'neutral'
            score = 0.0
            confidence = 0.5

            if 'positive' in result.lower():
                sentiment = 'positive'
                score = 0.7
            elif 'negative' in result.lower():
                sentiment = 'negative'
                score = -0.7

            # å˜—è©¦æå–æ•¸å€¼
            score_match = re.search(r'åˆ†æ•¸[:\s]+([-+]?\d*\.?\d+)', result)
            if score_match:
                score = float(score_match.group(1))

            conf_match = re.search(r'ä¿¡å¿ƒ[:\s]+(\d*\.?\d+)', result)
            if conf_match:
                confidence = float(conf_match.group(1))

            return {
                'sentiment': sentiment,
                'score': score,
                'confidence': confidence
            }

        return super().sentiment_analysis(text, **kwargs)

    def extract_keywords(self, text: str, top_k: int = 5, **kwargs) -> List[str]:
        """
        é—œéµå­—æå–

        Args:
            text: è¦æå–é—œéµå­—çš„æ–‡å­—
            top_k: æå–å‰ K å€‹é—œéµå­—
            **kwargs: é¡å¤–åƒæ•¸

        Returns:
            List[str]: é—œéµå­—åˆ—è¡¨
        """
        if not self._initialized:
            return super().extract_keywords(text, top_k, **kwargs)

        system = "ä½ æ˜¯é—œéµå­—æå–å°ˆå®¶ã€‚å¾æ–‡å­—ä¸­æå–æœ€é‡è¦çš„é—œéµå­—ã€‚"

        prompt = f"""è«‹å¾ä»¥ä¸‹æ–‡å­—ä¸­æå– {top_k} å€‹æœ€é‡è¦çš„é—œéµå­—:

{text[:1000]}

åªåˆ—å‡ºé—œéµå­—,ç”¨é€—è™Ÿåˆ†éš”,ä¸éœ€è¦å…¶ä»–æ–‡å­—ã€‚

é—œéµå­—:"""

        result = self._generate(prompt, system=system, max_tokens=128, temperature=0.3)

        if result:
            # è§£æé—œéµå­—
            keywords = [k.strip() for k in result.split(',')]
            return keywords[:top_k]

        return []

    def summarize(self, text: str, max_length: int = 200, **kwargs) -> str:
        """
        æ‘˜è¦ç”Ÿæˆ

        Args:
            text: è¦æ‘˜è¦çš„æ–‡å­—
            max_length: æœ€å¤§é•·åº¦
            **kwargs: é¡å¤–åƒæ•¸

        Returns:
            str: æ‘˜è¦æ–‡å­—
        """
        if not self._initialized:
            return super().summarize(text, max_length, **kwargs)

        system = "ä½ æ˜¯æ‘˜è¦ç”Ÿæˆå°ˆå®¶ã€‚æä¾›ç°¡æ½”æº–ç¢ºçš„æ‘˜è¦ã€‚"

        prompt = f"""è«‹å°‡ä»¥ä¸‹æ–‡å­—æ‘˜è¦ç‚º {max_length} å­—ä»¥å…§:

{text}

æ‘˜è¦:"""

        result = self._generate(prompt, system=system, max_tokens=512, temperature=0.5)
        return result or super().summarize(text, max_length, **kwargs)

    def _format_holdings_data(self, holdings_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æŒè‚¡æ•¸æ“šç‚ºå¯è®€æ–‡å­—"""
        lines = []
        for ticker, data in holdings_data.items():
            lines.append(f"### {ticker}")
            for key, value in data.items():
                lines.append(f"- {key}: {value}")
            lines.append("")
        return '\n'.join(lines)

    def get_inference_count(self) -> int:
        """
        å–å¾—æ¨è«–æ¬¡æ•¸

        Returns:
            int: æ¨è«–æ¬¡æ•¸
        """
        return self._inference_count

    def reset_inference_count(self):
        """é‡ç½®æ¨è«–æ¬¡æ•¸"""
        self._inference_count = 0

    def get_status(self) -> Dict[str, Any]:
        """
        å–å¾—åˆ†æå™¨ç‹€æ…‹

        Returns:
            Dict[str, Any]: ç‹€æ…‹å­—å…¸
        """
        status = super().get_status()
        status['model'] = self.model
        status['host'] = self.host
        status['inference_count'] = self._inference_count
        return status
